{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c5b2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm #para poder ver las barritas de % cargandose cuando va iterando\n",
    "from PIL import Image as im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "632d33e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para usar solo 24 cores que me dijo NW\n",
    "torch.set_num_threads(24)\n",
    "\n",
    "# Set seeds for reproducibility (PyTorch, Python, Numpy)\n",
    "matricola = 2013031\n",
    "torch.manual_seed(matricola)\n",
    "random.seed(matricola)\n",
    "np.random.seed(matricola)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d0681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the model \n",
    "def saveModel(model): \n",
    "    path = \"./Modelos_Fiteados/AEC/AEC_ultima.pth\" \n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af2e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bajo el MNIST\n",
    "train_dataset = torchvision.datasets.MNIST('./', train=True, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST('./', train=False, download=True)\n",
    "\n",
    "m=len(train_dataset)\n",
    "\n",
    "train_data, val_data = random_split(train_dataset, [int(m-m*0.2), int(m*0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5865bac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 ---- 12000\n"
     ]
    }
   ],
   "source": [
    "print(int(m-m*0.2),'----',int(m*0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e34bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Bajo el FashionMNIST\n",
    "# train_dataset = torchvision.datasets.FashionMNIST('./', train=True, download=True)\n",
    "# test_dataset = torchvision.datasets.FashionMNIST('./', train=False, download=True)\n",
    "\n",
    "# m=len(train_dataset)\n",
    "\n",
    "# train_data, val_data = random_split(train_dataset, [int(m-m*0.2), int(m*0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cd206f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [x[0] for x in train_data]\n",
    "y_train = [x[1] for x in train_data]\n",
    "\n",
    "X_val = [x[0] for x in val_data]\n",
    "Y_val = [x[1] for x in val_data]\n",
    "\n",
    "X_test = [x[0] for x in test_dataset]\n",
    "Y_test = [x[1] for x in test_dataset]\n",
    "\n",
    "RX_train = [0]*(10*len(X_train))\n",
    "RY_train = [0]*(10*len(X_train))\n",
    "\n",
    "RX_val = [0]*(10*len(X_val))\n",
    "RY_val = [0]*(10*len(X_val))\n",
    "\n",
    "RX_test = [0]*(10*len(X_test))\n",
    "RY_test = [0]*(10*len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1acd6fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotador = torchvision.transforms.functional.rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc98b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    for j in range(10):\n",
    "        ang = random.randint(-60,60)\n",
    "        RX_train[i*10+j]=rotador(X_train[i],ang)\n",
    "        RY_train[i*10+j]=X_train[i]\n",
    "        \n",
    "for i in range(len(X_val)):\n",
    "    for j in range(10):\n",
    "        ang = random.randint(-60,60)\n",
    "        RX_val[i*10+j]=rotador(X_val[i],ang)\n",
    "        RY_val[i*10+j]=X_val[i]\n",
    "    \n",
    "for i in range(len(X_test)):\n",
    "    for j in range(10):\n",
    "        ang = random.randint(-60,60)\n",
    "        RX_test[i*10+j]=rotador(X_test[i],ang)\n",
    "        RY_test[i*10+j]=X_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42abe38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(RX_test[0].mode)\n",
    "\n",
    "# #torchvision.transforms.ToTensor[SOURCE]\n",
    "# # Convert a PIL Image or numpy.ndarray to tensor. This transform does not support torchscript.\n",
    "\n",
    "# # Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor \n",
    "# # of shape (C x H x W) in the range [0.0, 1.0] \n",
    "# # if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1)\n",
    "# # or if the numpy.ndarray has dtype = np.uint8\n",
    "\n",
    "# # In the other cases, tensors are returned without scaling.\n",
    "\n",
    "\n",
    "# #ES L asi que tengo toda la data normalizada despues ! Joya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae394db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot some samples\n",
    "# fig, axs = plt.subplots(5, 5, figsize=(8,8))\n",
    "# i = 0\n",
    "# for ax in axs.flatten():\n",
    "#     # random.choice allows to randomly sample from a list-like object \n",
    "#     #(basically anything that can be accessed with an index, like our dataset)\n",
    "#     #img, label = random.choice(train_dataset)\n",
    "#     ax.imshow(np.array(RX_train[i*20]), cmap='gist_gray')\n",
    "# #     ax.set_title(f'Angle: {round((Rang_train[i*20]),2)}')\n",
    "#     ax.set_xticks([])\n",
    "#     ax.set_yticks([])\n",
    "#     i +=1\n",
    "# #plt.savefig('./Img/clothe_samples.svg', format='svg')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b0f5516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hago la transformacion a tensores\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "\n",
    "#los convierto a tensores con la transformacion\n",
    "tensor_RX_train = [to_tensor(RX_train[i]).unsqueeze(0) for i in range(len(RX_train))]\n",
    "tensor_RX_train = torch.cat(tensor_RX_train)\n",
    "\n",
    "tensor_RY_train = [to_tensor(RY_train[i]).unsqueeze(0) for i in range(len(RY_train))]\n",
    "tensor_RY_train = torch.cat(tensor_RY_train)\n",
    "\n",
    "tensor_RX_val = [to_tensor(RX_val[i]).unsqueeze(0) for i in range(len(RX_val))]\n",
    "tensor_RX_val = torch.cat(tensor_RX_val)\n",
    "\n",
    "tensor_RY_val = [to_tensor(RY_val[i]).unsqueeze(0) for i in range(len(RY_val))]\n",
    "tensor_RY_val = torch.cat(tensor_RY_val)\n",
    "\n",
    "tensor_RX_test = [to_tensor(RX_test[i]).unsqueeze(0) for i in range(len(RX_test))]\n",
    "tensor_RX_test = torch.cat(tensor_RX_test)\n",
    "\n",
    "tensor_RY_test = [to_tensor(RY_test[i]).unsqueeze(0) for i in range(len(RY_test))]\n",
    "tensor_RY_test = torch.cat(tensor_RY_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db98d958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datasets\n",
    "tensor_datatrain = TensorDataset(tensor_RX_train, tensor_RY_train)\n",
    "train_loader = DataLoader(tensor_datatrain, batch_size=5000, shuffle=True)\n",
    "\n",
    "tensor_dataval = TensorDataset(tensor_RX_val, tensor_RY_val)\n",
    "val_loader = DataLoader(tensor_dataval, batch_size=5000, shuffle=True)\n",
    "\n",
    "tensor_datatest = TensorDataset(tensor_RX_test, tensor_RY_test)\n",
    "test_loader = DataLoader(tensor_datatest, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c2539e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, nf, latent_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        ### Encoder\n",
    "        self.encoder = nn.Sequential(nn.Conv2d(in_channels  = 1,       # First convolutional layer\n",
    "                                               out_channels = nf,\n",
    "                                               kernel_size  = 3,\n",
    "                                               stride       = 1,\n",
    "                                               padding      = 1),\n",
    "                                     nn.ReLU(True),                    \n",
    "                                     nn.Conv2d(in_channels  = nf,      # Second convolutional layer\n",
    "                                               out_channels = 2 * nf,\n",
    "                                               kernel_size  = 3,\n",
    "                                               stride       = 1,\n",
    "                                               padding      = 1),\n",
    "#                                      nn.BatchNorm2d(16),\n",
    "                                     nn.ReLU(True),                    \n",
    "                                     nn.Conv2d(in_channels  = 2 * nf,  # Third convolutional layer\n",
    "                                               out_channels = 4 * nf,\n",
    "                                               kernel_size  = 3,\n",
    "                                               stride       = 2,\n",
    "                                               padding      = 1),       #Out 14*14*32\n",
    "                                     nn.ReLU(True))\n",
    "        \n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        ### Linear section\n",
    "        self.encoder_lin = nn.Sequential(nn.Linear(14*14*(4*nf), 1024),\n",
    "                                         nn.ReLU(True),\n",
    "                                         nn.Linear(1024, latent_dim))\n",
    "        \n",
    "        ### Decoder\n",
    "        \n",
    "        self.decoder_lin = nn.Sequential(nn.Linear(latent_dim, 1024),\n",
    "                                         nn.ReLU(True),\n",
    "                                         nn.Linear(1024, 14*14*(4*nf)),\n",
    "                                         nn.ReLU(True))\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1,\n",
    "                                      unflattened_size=((4*nf), 14, 14))\n",
    "\n",
    "        self.decoder = nn.Sequential(nn.ConvTranspose2d(in_channels    = 4 * nf,   # First transposed convolution\n",
    "                                                        out_channels   = 2 * nf,\n",
    "                                                        kernel_size    = 3,\n",
    "                                                        stride         = 2,\n",
    "                                                        padding        = 1,\n",
    "                                                        output_padding = 1),\n",
    "#                                      nn.BatchNorm2d(16),\n",
    "                                     nn.ReLU(True),\n",
    "                                     nn.ConvTranspose2d(in_channels    = 2 * nf,    # Second transposed convolution\n",
    "                                                        out_channels   = nf,\n",
    "                                                        kernel_size    = 3,\n",
    "                                                        stride         = 1,\n",
    "                                                        padding        = 1,\n",
    "                                                        output_padding = 0),\n",
    "                                     nn.ReLU(True),\n",
    "                                     nn.ConvTranspose2d(in_channels    = nf,        # Third transposed convolution\n",
    "                                                        out_channels   = 1,\n",
    "                                                        kernel_size    = 3,\n",
    "                                                        stride         = 1,\n",
    "                                                        padding        = 1,\n",
    "                                                        output_padding = 0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x1 = torch.clone(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.encoder_lin(x)\n",
    "        x = self.decoder_lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.decoder(x)\n",
    "        return x, x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "971c366e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (encoder_lin): Sequential(\n",
       "    (0): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  )\n",
       "  (decoder_lin): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=1024, out_features=12544, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(64, 14, 14))\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): ConvTranspose2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate     = 1e-3\n",
    "regularization    = 1e-4\n",
    "nf                = 16\n",
    "latent_dim        = 128\n",
    "\n",
    "AEC = Autoencoder(nf,latent_dim)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "params_to_optimize = [{'params': AEC.encoder.parameters()},\n",
    "                      {'params': AEC.decoder.parameters()}]\n",
    "\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=learning_rate, weight_decay=regularization)\n",
    "\n",
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "#Send model to device\n",
    "AEC.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe88756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AEC.load_state_dict(torch.load(\"./Modelos_Fiteados/AEC/AEC_1024_2.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef9a2929",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training function\n",
    "def train_epoch(AEC, device, dataloader, loss_fn, optimizer):\n",
    "    AEC.train()\n",
    "    train_loss = []\n",
    "    for data, label in dataloader:\n",
    "        # Move data to device\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        # process\n",
    "        processed = AEC.forward(data)[0]\n",
    "        # Compute loss\n",
    "        loss = loss_fn(processed, label)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ###\n",
    "        loss = loss.detach().cpu().numpy()\n",
    "        train_loss.append(loss)\n",
    "    return np.mean(train_loss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "210b4b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing function\n",
    "def test_epoch(AEC, device, dataloader, loss_fn):\n",
    "    AEC.eval()\n",
    "    test_loss = []\n",
    "    with torch.no_grad():\n",
    "        for data, label in dataloader:\n",
    "            # Move tensor to the proper device\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "            # output\n",
    "            processed = AEC.forward(data)[0]\n",
    "            # Compute loss\n",
    "            loss = loss_fn(processed, label)\n",
    "            #Save test loss for this batch\n",
    "            loss = loss.detach().cpu().numpy()\n",
    "            test_loss.append(loss)\n",
    "    return np.mean(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9045720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_ae_outputs(AEC, n=10):\n",
    "#     plt.figure(figsize=(16,4.5))\n",
    "#     targets = tensor_datatest.targets.numpy()\n",
    "#     t_idx = {i:np.where(targets==i)[0][0] for i in range(n)}\n",
    "#     for i in range(n):\n",
    "#         ax = plt.subplot(2,n,i+1)\n",
    "#         img = tensor_datatest[t_idx[i]][0].unsqueeze(0).to(device)\n",
    "#         encoder.eval()\n",
    "#         decoder.eval()\n",
    "#         with torch.no_grad():\n",
    "#             rec_img  = decoder(encoder(img))\n",
    "#         plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "#         ax.get_xaxis().set_visible(False)\n",
    "#         ax.get_yaxis().set_visible(False)\n",
    "#         if i == n//2:\n",
    "#             ax.set_title('Original images')\n",
    "#         ax = plt.subplot(2, n, i + 1 + n)\n",
    "#         plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "#         ax.get_xaxis().set_visible(False)\n",
    "#         ax.get_yaxis().set_visible(False)\n",
    "#         if i == n//2:\n",
    "#             ax.set_title('Reconstructed images')\n",
    "#         plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8f39e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_stopping(train_loss, validation_loss, min_delta, tolerance):\n",
    "\n",
    "    counter = 0\n",
    "    if (validation_loss - train_loss) > min_delta:\n",
    "        counter +=1\n",
    "        if counter >= tolerance:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "320cd101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▌                                                                           | 1/30 [08:55<4:18:36, 535.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 1/30 \t train loss_1 0.08724325895309448 \t train loss_2 0.06387387961149216 \t val loss 0.06383249908685684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▏                                                                        | 2/30 [17:53<4:10:32, 536.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 2/30 \t train loss_1 0.060944508761167526 \t train loss_2 0.058346208184957504 \t val loss 0.058201324194669724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▊                                                                      | 3/30 [27:02<4:04:09, 542.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 3/30 \t train loss_1 0.056329261511564255 \t train loss_2 0.05443910136818886 \t val loss 0.054224539548158646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▍                                                                   | 4/30 [35:59<3:54:09, 540.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 4/30 \t train loss_1 0.0532599538564682 \t train loss_2 0.05203661322593689 \t val loss 0.05180441215634346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████                                                                 | 5/30 [45:04<3:45:48, 541.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 5/30 \t train loss_1 0.051224227994680405 \t train loss_2 0.050180599093437195 \t val loss 0.049951422959566116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▌                                                              | 6/30 [54:00<3:35:59, 539.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 6/30 \t train loss_1 0.049735862761735916 \t train loss_2 0.04883076623082161 \t val loss 0.04860011860728264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|█████████████████▋                                                          | 7/30 [1:02:56<3:26:26, 538.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 7/30 \t train loss_1 0.04864149168133736 \t train loss_2 0.048546671867370605 \t val loss 0.04832061007618904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|████████████████████▎                                                       | 8/30 [1:11:53<3:17:17, 538.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 8/30 \t train loss_1 0.04763292148709297 \t train loss_2 0.04698904976248741 \t val loss 0.04676090553402901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██████████████████████▊                                                     | 9/30 [1:20:48<3:08:01, 537.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 9/30 \t train loss_1 0.04682819917798042 \t train loss_2 0.0462191142141819 \t val loss 0.0459911972284317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|█████████████████████████                                                  | 10/30 [1:31:32<3:10:01, 570.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 10/30 \t train loss_1 0.0463634692132473 \t train loss_2 0.04559098556637764 \t val loss 0.04535786807537079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███████████████████████████▍                                               | 11/30 [1:43:25<3:14:24, 613.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 11/30 \t train loss_1 0.04557189345359802 \t train loss_2 0.04493182525038719 \t val loss 0.044705625623464584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████████████████████████                                             | 12/30 [1:55:28<3:14:10, 647.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 12/30 \t train loss_1 0.04508045315742493 \t train loss_2 0.04443703219294548 \t val loss 0.0442068986594677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████████████████████████████████▌                                          | 13/30 [2:06:55<3:06:48, 659.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 13/30 \t train loss_1 0.04476649686694145 \t train loss_2 0.04418747127056122 \t val loss 0.04395231232047081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|███████████████████████████████████                                        | 14/30 [2:18:25<2:58:15, 668.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 14/30 \t train loss_1 0.04430386424064636 \t train loss_2 0.04363253340125084 \t val loss 0.04339981451630592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████▌                                     | 15/30 [2:30:28<2:51:11, 684.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 15/30 \t train loss_1 0.04391178861260414 \t train loss_2 0.043303389102220535 \t val loss 0.04307172819972038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|████████████████████████████████████████                                   | 16/30 [2:42:06<2:40:44, 688.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 16/30 \t train loss_1 0.04362541437149048 \t train loss_2 0.04326711595058441 \t val loss 0.04304642602801323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|██████████████████████████████████████████▌                                | 17/30 [2:53:26<2:28:40, 686.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 17/30 \t train loss_1 0.04353995993733406 \t train loss_2 0.043859634548425674 \t val loss 0.04363283887505531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████                              | 18/30 [3:05:10<2:18:19, 691.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 18/30 \t train loss_1 0.04289691150188446 \t train loss_2 0.04343707859516144 \t val loss 0.04322316125035286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|███████████████████████████████████████████████▌                           | 19/30 [3:16:41<2:06:45, 691.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 19/30 \t train loss_1 0.04285407066345215 \t train loss_2 0.04219025745987892 \t val loss 0.04196320101618767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████████                         | 20/30 [3:28:38<1:56:29, 698.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 20/30 \t train loss_1 0.04258148372173309 \t train loss_2 0.043487537652254105 \t val loss 0.04327849671244621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████▌                      | 21/30 [3:40:18<1:44:54, 699.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 21/30 \t train loss_1 0.042367398738861084 \t train loss_2 0.04221336171030998 \t val loss 0.04198524355888367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████████████████████████████▉                    | 22/30 [3:52:14<1:33:55, 704.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 22/30 \t train loss_1 0.04219767078757286 \t train loss_2 0.04198750853538513 \t val loss 0.04177433252334595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████████▌                 | 23/30 [4:03:39<1:21:30, 698.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 23/30 \t train loss_1 0.04196948930621147 \t train loss_2 0.04342874884605408 \t val loss 0.043225374072790146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████               | 24/30 [4:15:34<1:10:19, 703.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 24/30 \t train loss_1 0.04186807945370674 \t train loss_2 0.04159406200051308 \t val loss 0.041370946913957596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████████████████████████████████████▏            | 25/30 [4:25:57<56:36, 679.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 25/30 \t train loss_1 0.04160332679748535 \t train loss_2 0.04101384058594704 \t val loss 0.04079682007431984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|██████████████████████████████████████████████████████████████████▋          | 26/30 [4:34:52<42:23, 635.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 26/30 \t train loss_1 0.04139801487326622 \t train loss_2 0.041031066328287125 \t val loss 0.0408175103366375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████▎       | 27/30 [4:43:47<30:17, 605.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 27/30 \t train loss_1 0.04123920202255249 \t train loss_2 0.04068225249648094 \t val loss 0.04047028347849846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|███████████████████████████████████████████████████████████████████████▊     | 28/30 [4:52:42<19:29, 584.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 28/30 \t train loss_1 0.041052136570215225 \t train loss_2 0.04109294340014458 \t val loss 0.040889471769332886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|██████████████████████████████████████████████████████████████████████████▍  | 29/30 [5:01:38<09:30, 570.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 29/30 \t train loss_1 0.040943920612335205 \t train loss_2 0.04099145531654358 \t val loss 0.04077664017677307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 30/30 [5:10:34<00:00, 621.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 30/30 \t train loss_1 0.04092252254486084 \t train loss_2 0.040170036256313324 \t val loss 0.03995911404490471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "diz_loss = {'train_loss_1':[],'train_loss_2':[],'val_loss':[]}\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train_loss_1 = train_epoch(AEC,\n",
    "                               device,\n",
    "                               train_loader,\n",
    "                               loss_fn,\n",
    "                               optim)\n",
    "    train_loss_2 = test_epoch(AEC,\n",
    "                              device,\n",
    "                              train_loader,\n",
    "                              loss_fn)\n",
    "    val_loss = test_epoch(AEC,\n",
    "                          device,\n",
    "                          val_loader,\n",
    "                          loss_fn)\n",
    "    print('\\n EPOCH {}/{} \\t train loss_1 {} \\t train loss_2 {} \\t val loss {}'.format(epoch + 1, num_epochs,train_loss_1,train_loss_2,val_loss))\n",
    "    diz_loss['train_loss_1'].append(train_loss_1)\n",
    "    diz_loss['train_loss_2'].append(train_loss_2)\n",
    "    diz_loss['val_loss'].append(val_loss)\n",
    "#     plot_ae_outputs(AEC, n=10)\n",
    "# early stopping\n",
    "    if early_stopping(train_loss_2, val_loss, min_delta=0.001, tolerance = 5):\n",
    "      print(\"We are at epoch:\", i)\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c55afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModel(AEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93b67257",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./Modelos_Fiteados/losses/AEC/NUEVAS/train_ultimo_1',diz_loss['train_loss_1'])\n",
    "np.savetxt('./Modelos_Fiteados/losses/AEC/NUEVAS/train_ultimo_2',diz_loss['train_loss_2'])\n",
    "np.savetxt('./Modelos_Fiteados/losses/AEC/NUEVAS/val_ultimo',diz_loss['val_loss'])\n",
    "\n",
    "# train_loss = np.loadtxt()\n",
    "# test_loss = np.loadtxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf8c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch(AEC, device, test_loader, loss_fn).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb448ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot losses by epoch\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(diz_loss['train_loss_2'], linestyle='--', marker='o',  label='Train loss', c='mediumaquamarine')\n",
    "plt.plot(diz_loss['val_loss'], linestyle='--', marker='o', label='Valid loss', c='darkviolet')\n",
    "plt.xlabel('Época',fontsize=15)\n",
    "plt.ylabel('Loss',fontsize=15)\n",
    "plt.title(\"Función de costo\",fontsize=15)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.savefig('./Modelos_Fiteados/Imagenes/AEC/NUEVAS/errores_AEC.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c8afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot losses\n",
    "# plt.figure(figsize=(10,8))\n",
    "# plt.plot(diz_loss['train_loss'], label='Train')\n",
    "# plt.plot(diz_loss['val_loss'], label='Valid')\n",
    "\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Average Loss')\n",
    "# plt.legend()\n",
    "# #plt.title('loss')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b7460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = [110,121,130,140]\n",
    "\n",
    "fig, axs = plt.subplots(3, 4, figsize=(12,6))\n",
    "fig.suptitle('Original, rotada and reconstructed image',fontsize=15)\n",
    "fig.subplots_adjust(top=0.88)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in range (4):\n",
    "    img   = to_tensor(RX_test[elements[i]]).unsqueeze(0).to(device)\n",
    "    label = to_tensor(RY_test[elements[i]]).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        AEC.eval()\n",
    "        rec_img  = AEC(img)[0]        \n",
    "    # Plot the reconstructed image  \n",
    "    axs[i].imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "    axs[i].set_title('img')\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "    axs[i+4].imshow(label.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "    axs[i+4].set_title('original')\n",
    "    axs[i+4].set_xticks([])\n",
    "    axs[i+4].set_yticks([])\n",
    "    axs[i+8].imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "    axs[i+8].set_title('Reconstructed image')\n",
    "    axs[i+8].set_xticks([])\n",
    "    axs[i+8].set_yticks([])\n",
    "#     plt.savefig('./Modelos_Fiteados/Imagenes/AEC/recons_1024.png', format='png')\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(top=0.88)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a56073a",
   "metadata": {},
   "source": [
    "veamos activaciones a ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0414afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=140\n",
    "\n",
    "activaciones = np.empty(shape=(64,14,14))\n",
    "\n",
    "img   = to_tensor(RX_test[i]).unsqueeze(0).to(device)\n",
    "label = to_tensor(RY_test[i]).unsqueeze(0).to(device)\n",
    "with torch.no_grad():\n",
    "    AEC.eval()\n",
    "    activ = AEC.forward(img)[1]\n",
    "    activaciones = activ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffe309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(activaciones[0,0])\n",
    "\n",
    "plt.imshow(activaciones[0,0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab24af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(activaciones.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fefcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(8, 8, figsize=(8,8))\n",
    "i = 0\n",
    "for ax in axs.flatten():\n",
    "    ax.imshow(activaciones[0,i], cmap='gist_gray')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    i +=1\n",
    "plt.tight_layout()\n",
    "plt.savefig('./Modelos_Fiteados/Imagenes/AEC/activaciones_1024_1s.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1474a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,j in AEC.named_parameters():\n",
    "#     print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69f9166",
   "metadata": {},
   "source": [
    "### Visualizacion de filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff160b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = [] \n",
    "conv_layers = [] \n",
    "model_children = list(AEC.encoder.children())\n",
    "\n",
    "# counter to keep count of the conv layers\n",
    "counter = 0 \n",
    "# append all the conv layers and their respective weights to the list\n",
    "for i in range(len(model_children)):\n",
    "    if type(model_children[i]) == nn.Conv2d:\n",
    "        counter += 1\n",
    "        model_weights.append(model_children[i].weight)\n",
    "        conv_layers.append(model_children[i])\n",
    "    elif type(model_children[i]) == nn.Sequential:\n",
    "        for j in range(len(model_children[i])):\n",
    "            for child in model_children[i][j].children():\n",
    "                if type(child) == nn.Conv2d:\n",
    "                    counter += 1\n",
    "                    model_weights.append(child.weight)\n",
    "                    conv_layers.append(child)\n",
    "print(f\"Total convolutional layers: {counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d8524",
   "metadata": {},
   "outputs": [],
   "source": [
    "for weight, conv in zip(model_weights, conv_layers):\n",
    "    # print(f\"WEIGHT: {weight} \\nSHAPE: {weight.shape}\")\n",
    "    print(f\"CONV: {conv} ====> SHAPE: {weight.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a67962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the first conv layer filters\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i, filter in enumerate(model_weights[0]):\n",
    "    plt.subplot(4, 4, i+1) # we have 3x3 filters and total of 8 (see printed shapes)\n",
    "    plt.imshow(filter[0, :, :].detach().cpu().numpy(), cmap='gist_gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('./Modelos_Fiteados/Imagenes/AEC/filtros_c1.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4564fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the 2nd conv layer filters\n",
    "plt.figure(figsize=(12,12))\n",
    "for i, filter in enumerate(model_weights[1]):\n",
    "    plt.subplot(4, 8, i+1) # we have 3x3 filters and total of 16 (see printed shapes)\n",
    "    plt.imshow(filter[0, :, :].detach().cpu().numpy(), cmap='gist_gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('./Modelos_Fiteados/Imagenes/AEC/filtros_c2.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d1678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the 3th conv layer filters\n",
    "plt.figure(figsize=(2*8,2*8))\n",
    "for i, filter in enumerate(model_weights[2]):\n",
    "    plt.subplot(8, 8, i+1) # we have 3x3 filters and total of 32 (see printed shapes)\n",
    "    plt.imshow(filter[0, :, :].detach().cpu().numpy(), cmap='gist_gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('./Modelos_Fiteados/Imagenes/AEC/filtros_c3.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2673811",
   "metadata": {},
   "source": [
    "Visualización del espacio latente con t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b23ad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_samples = []\n",
    "# for sample in tqdm(tensor_datatest):\n",
    "#     img = sample[0].unsqueeze(0).to(device)\n",
    "#     label = sample[1]\n",
    "#     # Encode image    \n",
    "#     AEC.eval()\n",
    "#     with torch.no_grad():\n",
    "#         encoded_img  = AEC.encoder(img)\n",
    "#     # Append to list\n",
    "#     encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "#     encoded_sample = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "#     encoded_sample['label'] = label\n",
    "#     encoded_samples.append(encoded_sample)\n",
    "# encoded_samples = pd.DataFrame(encoded_samples)\n",
    "# encoded_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4666bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_samples.to_csv('./Modelos_Fiteados/AEC/encoded_samples.csv', header=False, index=False)\n",
    "\n",
    "# # encoded_asmples =pd.read_csv('./Modelos_Fiteados/AEC/encoded_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c193c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "\n",
    "# px.scatter(encoded_samples,\n",
    "#            x='Enc. Variable 0',\n",
    "#            y='Enc. Variable 1',\n",
    "#            color=encoded_samples.label.astype(str),\n",
    "#            opacity=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2eedbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
