{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77205ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm #para poder ver las barritas de % cargandose cuando va iterando\n",
    "from PIL import Image as im\n",
    "\n",
    "#PyTorch\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "#Optuna\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f5dd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para usar solo 24 cores que me dijo NW\n",
    "\n",
    "torch.set_num_threads(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f8a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility (PyTorch, Python, Numpy)\n",
    "matricola = 2013031\n",
    "torch.manual_seed(matricola)\n",
    "random.seed(matricola)\n",
    "np.random.seed(matricola)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f216765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the model \n",
    "def saveModel(model): \n",
    "    path = \"./Modelos_Fiteados/REG/NUEVAS/2C_L1.pth\" \n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f528d5",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac936bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bajo el MNIST\n",
    "datatrain = torchvision.datasets.MNIST('./', train=True, download=True)\n",
    "datatest = torchvision.datasets.MNIST('./', train=False, download=True)\n",
    "\n",
    "m=len(datatrain)\n",
    "\n",
    "train_data, val_data = random_split(datatrain, [int(m-m*0.2), int(m*0.2)])\n",
    "\n",
    "#Lo guardo en listas en vez de tensores\n",
    "X_train = [x[0] for x in train_data]\n",
    "y_train = [x[1] for x in train_data]\n",
    "\n",
    "X_val = [x[0] for x in val_data]\n",
    "y_val = [x[1] for x in val_data]\n",
    "\n",
    "X_test = [x[0] for x in datatest]\n",
    "y_test = [x[1] for x in datatest]\n",
    "\n",
    "\n",
    "RX_train = [0]*(20*len(X_train))\n",
    "RY_train = [0]*(20*len(X_train))\n",
    "\n",
    "RX_val = [0]*(20*len(X_val))\n",
    "RY_val = [0]*(20*len(X_val))\n",
    "\n",
    "RX_test = [0]*(20*len(X_test))\n",
    "RY_test = [0]*(20*len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55613df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotador = torchvision.transforms.functional.rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90c5d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    for j in range(20):\n",
    "        ang = random.uniform(-60,60)\n",
    "        RX_train[i*20+j]=rotador(X_train[i],ang)\n",
    "        RY_train[i*20+j]=ang\n",
    "        \n",
    "for i in range(len(X_val)):\n",
    "    for j in range(20):\n",
    "        ang = random.uniform(-60,60)\n",
    "        RX_val[i*20+j]=rotador(X_val[i],ang)\n",
    "        RY_val[i*20+j]=ang\n",
    "    \n",
    "for i in range(len(X_test)):\n",
    "    for j in range(20):\n",
    "        ang = random.uniform(-60,60)\n",
    "        RX_test[i*20+j]=rotador(X_test[i],ang)\n",
    "        RY_test[i*20+j]=ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ead974",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(RX_train), len(RX_val), len(RX_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff42c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos si estan masomenos distribuidos\n",
    "plt.hist(RY_test,10)\n",
    "plt.title('Histograma de labels')\n",
    "plt.xlabel('label')\n",
    "plt.ylabel('Frecuencia')\n",
    "\n",
    "plt.show() #dibujamos el histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefa9e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some samples\n",
    "fig, axs = plt.subplots(5, 5, figsize=(8,8))\n",
    "i = 0\n",
    "for ax in axs.flatten():\n",
    "    ax.imshow(np.array(RX_train[i*20]), cmap='gist_gray')\n",
    "    ax.set_title(f'Angle: {RY_train[i*20]}')#{round((RY_train[i*20]),2)}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    i +=1\n",
    "#plt.savefig('./Modelos_Fiteados/Imagenes/REG/.png', format='png')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a8daebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hago la transformacion a tensores\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "\n",
    "#los convierto a tensores con la transformacion\n",
    "tensor_RX_train = [to_tensor(RX_train[i]).unsqueeze(0) for i in range(len(RX_train))]\n",
    "tensor_RX_train = torch.cat(tensor_RX_train)\n",
    "\n",
    "tensor_RY_train = torch.Tensor(RY_train).float()\n",
    "###\n",
    "tensor_RX_val = [to_tensor(RX_val[i]).unsqueeze(0) for i in range(len(RX_val))]\n",
    "tensor_RX_val = torch.cat(tensor_RX_val)\n",
    "\n",
    "tensor_RY_val = torch.Tensor(RY_val).float()\n",
    "###\n",
    "tensor_RX_test = [to_tensor(RX_test[i]).unsqueeze(0) for i in range(len(RX_test))]\n",
    "tensor_RX_test = torch.cat(tensor_RX_test)\n",
    "\n",
    "tensor_RY_test = torch.Tensor(RY_test).float()\n",
    "\n",
    "#creo los datatrian y datatest\n",
    "tensor_datatrain = TensorDataset(tensor_RX_train, tensor_RY_train)\n",
    "train_loader = DataLoader(tensor_datatrain, batch_size=5000, shuffle=True)\n",
    "\n",
    "tensor_dataval = TensorDataset(tensor_RX_val, tensor_RY_val)\n",
    "valid_loader = DataLoader(tensor_dataval, batch_size=5000, shuffle=True)\n",
    "\n",
    "tensor_datatest = TensorDataset(tensor_RX_test, tensor_RY_test)\n",
    "test_loader = DataLoader(tensor_datatest, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0577bbff",
   "metadata": {},
   "source": [
    "### Red 3C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9849fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,nf):\n",
    "        super(Net,self).__init__()\n",
    "#         ariquitecture\n",
    "        self.net = nn.Sequential(nn.Conv2d(in_channels  = 1,        # First convolutional layer\n",
    "                                           out_channels = nf,\n",
    "                                           kernel_size  = 3,\n",
    "                                           stride       = 2,\n",
    "                                           padding      = 1),\n",
    "                                 nn.ReLU(True),                     # OUT  [nf X 14 X 14]\n",
    "                                 nn.Conv2d(in_channels  = nf,        # Second convolutional layer\n",
    "                                           out_channels = 2 * nf,\n",
    "                                           kernel_size  = 3,\n",
    "                                           stride       = 2,\n",
    "                                           padding      = 1),\n",
    "                                 nn.ReLU(True),                      # OUT [2nf X 7 X 7]\n",
    "                                 nn.Conv2d(in_channels  = 2 * nf,     # Third convolutional layer\n",
    "                                           out_channels = 4 * nf,\n",
    "                                           kernel_size  = 3,\n",
    "                                           stride       = 2,\n",
    "                                           padding      = 0),\n",
    "                                 nn.ReLU(True),                     # OUT [4nf X 3 x 3]\n",
    "                                 nn.Flatten(start_dim=1),            # Flatten layer\n",
    "                                 nn.Linear(in_features  = ((4*nf)*3*3),\n",
    "                                           out_features = 128),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.Linear(in_features  = 128,\n",
    "                                           out_features = 64),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(in_features  = 64,\n",
    "                                           out_features = 1,\n",
    "                                           bias=False)\n",
    "                                )\n",
    "        \n",
    "    def forward(self, x, mode):\n",
    "        if (mode == \"Train\"):\n",
    "            self.net.train()\n",
    "        elif (mode == \"Test\"):\n",
    "            self.net.eval()            \n",
    "        # Apply encoder decoder\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "    \n",
    "    ###Training function\n",
    "    def train_epoch(self,device,dataloader, loss_fn, optimizer, verbose = True):\n",
    "        \"\"\"\n",
    "        This function train the network for one epoch\n",
    "        \"\"\"\n",
    "        # Train\n",
    "        train_loss = []\n",
    "        for data_batched, label_batched in dataloader:\n",
    "            # Move data to device\n",
    "            data_batched = data_batched.to(device)\n",
    "            label_batched = label_batched.to(device)\n",
    "            # process\n",
    "            processed = self.forward(data_batched,\"Train\")[:,0] #dimension del output para que la loss la entienda\n",
    "            # Compute loss\n",
    "            loss = loss_fn(processed, label_batched)\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            #Updata weights\n",
    "            optimizer.step()\n",
    "            #Save trai loss for this batch\n",
    "            loss_batch = loss.detach().cpu().numpy()\n",
    "            train_loss.append(loss_batch)\n",
    "        #Save the average train loss\n",
    "        train_loss = np.mean(train_loss)\n",
    "#         if verbose: print(f\"AVERAGE TRAIN LOSS: {train_loss}\")\n",
    "\n",
    "        return train_loss\n",
    "    \n",
    "    ### Testing function\n",
    "    def test_epoch(self,device, dataloader, loss_fn, verbose= True):\n",
    "        \"\"\"\n",
    "        This function test the network performance for one epoch of training\n",
    "        \"\"\"\n",
    "        test_loss = []\n",
    "        # Discable gradient tracking\n",
    "        with torch.no_grad():\n",
    "            for data_batched, label_batched in dataloader:\n",
    "                # Move data to device\n",
    "                data_batched = data_batched.to(device)\n",
    "                label_batched = label_batched.to(device)\n",
    "                # process\n",
    "                processed = self.forward(data_batched,\"Test\")[:,0]\n",
    "                # Compute loss\n",
    "                loss = loss_fn(processed, label_batched)\n",
    "                 #Save test loss for this batch\n",
    "                loss_batch = loss.detach().cpu().numpy()\n",
    "                test_loss.append(loss_batch)\n",
    "            #Save the average train loss\n",
    "            test_loss = np.mean(test_loss)\n",
    "#             if verbose: print(f\"AVERAGE TEST LOSS: {test_loss}\")\n",
    "\n",
    "        return test_loss\n",
    "    \n",
    "    def training_cycle(self, device, training_data, test_data, loss_fn, optim, num_epochs,\n",
    "                       keep_model=False, verbose= True):\n",
    "        \"\"\"\n",
    "        This function train the network for a desired number of epochs it also test the network \n",
    "        reconstruction performance and make plots comparing the input image and the reconstructed one\n",
    "        every 5 epochs.\n",
    "        \"\"\"\n",
    "        \n",
    "        diz_loss = {'train_loss_1':[], 'train_loss_2':[], 'val_loss':[]}\n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            train_loss_1 =train_epoch(CLASIF,\n",
    "                            device,\n",
    "                            train_loader,\n",
    "                            loss_fn,\n",
    "                            optimizer)\n",
    "            train_loss_2 = test_epoch(CLASIF,\n",
    "                          device,\n",
    "                          train_loader,\n",
    "                          loss_fn)\n",
    "            val_loss = test_epoch(CLASIF,\n",
    "                          device,\n",
    "                          valid_loader,\n",
    "                          loss_fn)\n",
    "            print('\\n EPOCH {}/{} \\t train loss_1 {} \\t train loss_2 {} \\t val loss {}'.format(epoch + 1, num_epochs,train_loss_1,train_loss_2,val_loss))\n",
    "            diz_loss['train_loss_1'].append(train_loss_1)\n",
    "            diz_loss['train_loss_2'].append(train_loss_2)\n",
    "            diz_loss['val_loss'].append(val_loss)\n",
    "            \n",
    "            \n",
    "#         #I keep track of losses for plots\n",
    "#         train_loss_1 = []\n",
    "#         train_loss_2 = []\n",
    "#         test_loss    = []\n",
    "#         i = 0\n",
    "#         for epoch in tqdm(range(num_epochs)):\n",
    "#             if verbose: print('EPOCH %d/%d' % (epoch + 1, num_epochs))\n",
    "#             ### Training (use the training function)\n",
    "#             tr_l = self.train_epoch(\n",
    "#                 device=device, \n",
    "#                 dataloader=training_data, \n",
    "#                 loss_fn=loss_fn, \n",
    "#                 optimizer=optim,\n",
    "#                 verbose = verbose)\n",
    "#             train_loss_1.append(tr_l)\n",
    "#             ### training_2  (use the training for loss)\n",
    "#             t_l = self.test_epoch(\n",
    "#                 device=device, \n",
    "#                 dataloader=training_data, \n",
    "#                 loss_fn=loss_fn,\n",
    "#                 verbose = verbose)\n",
    "#             train_loss_2.append(t_l)\n",
    "#             ### Validation  (use the testing function)\n",
    "#             t_l = self.test_epoch(\n",
    "#                 device=device, \n",
    "#                 dataloader=test_data, \n",
    "#                 loss_fn=loss_fn,\n",
    "#                 verbose = verbose)\n",
    "#             test_loss.append(t_l)\n",
    "\n",
    "        return diz_loss['train_loss_1'], diz_loss['train_loss_2'], diz_loss['val_loss']\n",
    "# train_loss_1, train_loss_2, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dede57e1",
   "metadata": {},
   "source": [
    "### Red 2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c85b2636",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):    \n",
    "    def __init__(self,nf):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, nf, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(nf, nf, 3)\n",
    "        self.fc1 = nn.Linear(nf*12*12, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.soft = nn.Softmax()\n",
    "\n",
    "    def forward(self, x, mode):\n",
    "        if (mode == \"Train\"):\n",
    "            self.train()\n",
    "        elif (mode == \"Test\"):\n",
    "            self.eval()\n",
    "        \n",
    "        # Apply net\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.drop(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    ### Training function\n",
    "    def train_epoch(self,device,dataloader, loss_fn, optimizer, verbose = True):\n",
    "        \"\"\"\n",
    "        This function train the network for one epoch\n",
    "        \"\"\"\n",
    "        # Train\n",
    "        train_loss = []\n",
    "        for data_batched, label_batched in dataloader:\n",
    "            # Move data to device\n",
    "            data_batched = data_batched.to(device)\n",
    "            label_batched = label_batched.to(device)\n",
    "            # process\n",
    "            processed = self.forward(data_batched,\"Train\")[:,0] #dimension del output para que la loss la entienda\n",
    "            # Compute loss\n",
    "            loss = loss_fn(processed, label_batched)\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            #Updata weights\n",
    "            optimizer.step()\n",
    "            #Save trai loss for this batch\n",
    "            loss_batch = loss.detach().cpu().numpy()\n",
    "            train_loss.append(loss_batch)\n",
    "        #Save the average train loss\n",
    "        train_loss = np.mean(train_loss)\n",
    "#         if verbose: print(f\"AVERAGE TRAIN LOSS: {train_loss}\")\n",
    "\n",
    "        return train_loss\n",
    "    \n",
    "    ### Testing function\n",
    "    def test_epoch(self,device, dataloader, loss_fn, verbose= True):\n",
    "        \"\"\"\n",
    "        This function test the network performance for one epoch of training\n",
    "        \"\"\"\n",
    "        test_loss = []\n",
    "        # Discable gradient tracking\n",
    "        with torch.no_grad():\n",
    "            for data_batched, label_batched in dataloader:\n",
    "                # Move data to device\n",
    "                data_batched = data_batched.to(device)\n",
    "                label_batched = label_batched.to(device)\n",
    "                # process\n",
    "                processed = self.forward(data_batched,\"Test\")[:,0]\n",
    "                # Compute loss\n",
    "                loss = loss_fn(processed, label_batched)\n",
    "                 #Save test loss for this batch\n",
    "                loss_batch = loss.detach().cpu().numpy()\n",
    "                test_loss.append(loss_batch)\n",
    "            #Save the average train loss\n",
    "            test_loss = np.mean(test_loss)\n",
    "#             if verbose: print(f\"AVERAGE TEST LOSS: {test_loss}\")\n",
    "\n",
    "        return test_loss\n",
    "    \n",
    "    def training_cycle(self, device, training_data, test_data, loss_fn, optim, num_epochs,\n",
    "                       keep_model=False, verbose= True):\n",
    "        \"\"\"\n",
    "        This function train the network for a desired number of epochs it also test the network \n",
    "        reconstruction performance and make plots comparing the input image and the reconstructed one\n",
    "        every 5 epochs.\n",
    "        \"\"\"\n",
    "        \n",
    "        diz_loss = {'train_loss_1':[], 'train_loss_2':[], 'val_loss':[]}\n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            train_loss_1 =train_epoch(CLASIF,\n",
    "                            device,\n",
    "                            train_loader,\n",
    "                            loss_fn,\n",
    "                            optimizer)\n",
    "            train_loss_2 = test_epoch(CLASIF,\n",
    "                          device,\n",
    "                          train_loader,\n",
    "                          loss_fn)\n",
    "            val_loss = test_epoch(CLASIF,\n",
    "                          device,\n",
    "                          valid_loader,\n",
    "                          loss_fn)\n",
    "            print('\\n EPOCH {}/{} \\t train loss_1 {} \\t train loss_2 {} \\t val loss {}'.format(epoch + 1, num_epochs,train_loss_1,train_loss_2,val_loss))\n",
    "            diz_loss['train_loss_1'].append(train_loss_1)\n",
    "            diz_loss['train_loss_2'].append(train_loss_2)\n",
    "            diz_loss['val_loss'].append(val_loss)\n",
    "            \n",
    "            \n",
    "#         #I keep track of losses for plots\n",
    "#         train_loss_1 = []\n",
    "#         train_loss_2 = []\n",
    "#         test_loss    = []\n",
    "#         i = 0\n",
    "#         for epoch in tqdm(range(num_epochs)):\n",
    "#             if verbose: print('EPOCH %d/%d' % (epoch + 1, num_epochs))\n",
    "#             ### Training (use the training function)\n",
    "#             tr_l = self.train_epoch(\n",
    "#                 device=device, \n",
    "#                 dataloader=training_data, \n",
    "#                 loss_fn=loss_fn, \n",
    "#                 optimizer=optim,\n",
    "#                 verbose = verbose)\n",
    "#             train_loss_1.append(tr_l)\n",
    "#             ### training_2  (use the training for loss)\n",
    "#             t_l = self.test_epoch(\n",
    "#                 device=device, \n",
    "#                 dataloader=training_data, \n",
    "#                 loss_fn=loss_fn,\n",
    "#                 verbose = verbose)\n",
    "#             train_loss_2.append(t_l)\n",
    "#             ### Validation  (use the testing function)\n",
    "#             t_l = self.test_epoch(\n",
    "#                 device=device, \n",
    "#                 dataloader=test_data, \n",
    "#                 loss_fn=loss_fn,\n",
    "#                 verbose = verbose)\n",
    "#             test_loss.append(t_l)\n",
    "\n",
    "        return diz_loss['train_loss_1'], diz_loss['train_loss_2'], diz_loss['val_loss']\n",
    "# train_loss_1, train_loss_2, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62831c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 30\n",
    "\n",
    "#RED CON 3C\n",
    "# nf = 8\n",
    "\n",
    "#RED CON 2C\n",
    "nf = 64\n",
    "\n",
    "# Inicializamos la red\n",
    "model = Net(nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84358cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (drop): Dropout(p=0.25, inplace=False)\n",
       "  (soft): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definimos la loss function\n",
    "# loss_fn = nn.MSELoss()\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Definimos el optimizador\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001 , weight_decay=0.0001)\n",
    "\n",
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "#Send model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3021bbc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/30 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loss_1, train_loss_2, valid_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mkeep_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mNet.training_cycle\u001b[0;34m(self, device, training_data, test_data, loss_fn, optim, num_epochs, keep_model, verbose)\u001b[0m\n\u001b[1;32m     90\u001b[0m diz_loss \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss_1\u001b[39m\u001b[38;5;124m'\u001b[39m:[], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss_2\u001b[39m\u001b[38;5;124m'\u001b[39m:[], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m:[]}\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_epochs)):\n\u001b[0;32m---> 92\u001b[0m     train_loss_1 \u001b[38;5;241m=\u001b[39m\u001b[43mtrain_epoch\u001b[49m(CLASIF,\n\u001b[1;32m     93\u001b[0m                     device,\n\u001b[1;32m     94\u001b[0m                     train_loader,\n\u001b[1;32m     95\u001b[0m                     loss_fn,\n\u001b[1;32m     96\u001b[0m                     optimizer)\n\u001b[1;32m     97\u001b[0m     train_loss_2 \u001b[38;5;241m=\u001b[39m test_epoch(CLASIF,\n\u001b[1;32m     98\u001b[0m                   device,\n\u001b[1;32m     99\u001b[0m                   train_loader,\n\u001b[1;32m    100\u001b[0m                   loss_fn)\n\u001b[1;32m    101\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m test_epoch(CLASIF,\n\u001b[1;32m    102\u001b[0m                   device,\n\u001b[1;32m    103\u001b[0m                   valid_loader,\n\u001b[1;32m    104\u001b[0m                   loss_fn)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_epoch' is not defined"
     ]
    }
   ],
   "source": [
    "train_loss_1, train_loss_2, valid_loss = model.training_cycle(device,\n",
    "                                train_loader,\n",
    "                                valid_loader,\n",
    "                                loss_fn,\n",
    "                                optimizer,\n",
    "                                max_epochs,\n",
    "                                keep_model=False,\n",
    "                                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a6f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saveModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e6a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./Modelos_Fiteados/REG/3C_L1.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ff375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('./Modelos_Fiteados/losses/REG/Nuevas_loss/errorTrain_3CL1',train_loss_1)\n",
    "np.savetxt('./Modelos_Fiteados/losses/REG/Nuevas_loss/errorTrain_3CL1',train_loss_2)\n",
    "np.savetxt('./Modelos_Fiteados/losses/REG/Nuevas_loss/errorVal_3CL1',valid_loss)\n",
    "\n",
    "# train_loss = np.loadtxt('./Modelos_Fiteados/losses/REG/trainloss_2C_L1')\n",
    "# valid_loss = np.loadtxt('./Modelos_Fiteados/losses/REG/validloss_2C_L1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d98b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses by epoch\n",
    "plt.figure(figsize=(7,5))\n",
    "# plt.plot(train_loss_1, linestyle='--', marker='o',  label='Train 1 loss', c='mediumaquamarine')\n",
    "plt.plot(train_loss_2, linestyle='--', marker='o',  label='Train 2 loss', c='green')\n",
    "plt.plot(valid_loss, linestyle='--', marker='o', label='Valid loss', c='darkviolet')\n",
    "plt.xlabel('Época',fontsize=15)\n",
    "plt.ylabel('Loss',fontsize=15)\n",
    "plt.title(\"Función de costo ...........\",fontsize=15)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.savefig('./Modelos_Fiteados/Imagenes/REG/errores_........_.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = []\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs, \"Test\")\n",
    "        outputs = outputs.detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        prediccion.append([outputs[0][0],labels[0]])\n",
    "        #print(outputs)\n",
    "prediccion = np.array(prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d644e2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('./Modelos_Fiteados/REG/predic_3C_L1',prediccion)\n",
    "\n",
    "prediccion = np.loadtxt('./Modelos_Fiteados/REG/predic_3C_L1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7275445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(7,5))\n",
    "plt.scatter(prediccion[:,1],prediccion[:,0], marker=\"+\", s=1, alpha=.2, c='blueviolet')\n",
    "plt.plot(np.linspace(-60, 60, num=100),np.linspace(-60, 60, num=100), linestyle='--', c='orange')\n",
    "plt.xlabel('Valor REAL',fontsize=15)\n",
    "plt.ylabel('Valor PREDICHO',fontsize=15)\n",
    "plt.title(\"Dispersión de valores predichos\",fontsize=15)\n",
    "plt.xlim(-60,60)\n",
    "plt.savefig('./Modelos_Fiteados/Imagenes/REG/disper_3C_L1.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53aff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.scatter(prediccion[:,0],[i for i in range(len(prediccion[:,0]))],alpha=0.05)\n",
    "# plt.scatter(prediccion[:,1],[i for i in range(len(prediccion[:,1]))],alpha=0.05)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3170900b",
   "metadata": {},
   "source": [
    "### Vamos a discretizar las cosas asi vemos una especie de CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bc74d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = np.loadtxt('./Modelos_Fiteados/REG/predic_2C_L1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33db4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for i in range(len(prediccion)):\n",
    "    if -60<= prediccion[i,0]< -45:\n",
    "        prediccion[i,0]=0\n",
    "    elif -45 <= prediccion[i,0] < -30:\n",
    "        prediccion[i,0]=1\n",
    "    elif -30<= prediccion[i,0] < -15:\n",
    "        prediccion[i,0]=2\n",
    "    elif -15 <= prediccion[i,0] < 0:\n",
    "        prediccion[i,0]=3\n",
    "    elif 0 <= prediccion[i,0] <15:\n",
    "        prediccion[i,0]=4\n",
    "    elif 15 <= prediccion[i,0] <30:\n",
    "        prediccion[i,0]=5\n",
    "    elif 30 <= prediccion[i,0] <45:\n",
    "        prediccion[i,0]=6\n",
    "    else:\n",
    "        prediccion[i,0]=7        \n",
    "        \n",
    "i=0\n",
    "for i in range(len(prediccion)):\n",
    "    if -60 <= prediccion[i,1]< -45:\n",
    "        prediccion[i,1]=0\n",
    "    elif -45 <= prediccion[i,1] < -30:\n",
    "        prediccion[i,1]=1\n",
    "    elif -30<= prediccion[i,1] < -15:\n",
    "        prediccion[i,1]=2\n",
    "    elif -15 <= prediccion[i,1] < 0:\n",
    "        prediccion[i,1]=3\n",
    "    elif 0 <= prediccion[i,1] <15:\n",
    "        prediccion[i,1]=4\n",
    "    elif 15 <= prediccion[i,1] <30:\n",
    "        prediccion[i,1]=5\n",
    "    elif 30 <= prediccion[i,1] <45:\n",
    "        prediccion[i,1]=6\n",
    "    else:\n",
    "        prediccion[i,1]=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ec63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = prediccion[:,0]\n",
    "pred = prediccion[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a762d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confussion_plot(real, prediction):\n",
    "    categories = ['Clase 1', 'Clase 2', 'Clase 3', 'Clase 4', 'Clase 5', 'Clase 6', 'Clase 7', 'Clase 8']\n",
    "\n",
    "    array = confusion_matrix(real, prediction)#, normalize=\"true\")\n",
    "    df_cm = pd.DataFrame(array, index = [i for i in categories], columns = [i for i in categories])\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,7))\n",
    "    sn.heatmap(df_cm, annot=True, fmt='.2f', cmap='viridis')\n",
    "    plt.ylabel(\"Etiqueta\",fontsize=15)\n",
    "    plt.xlabel(\"Predicción\",fontsize=15)\n",
    "    plt.title(\"Matríz de confusión\",fontsize=15)\n",
    "    plt.savefig('./Modelos_Fiteados/Imagenes/REG/CM_2C_L1.png', format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b14e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "confussion_plot(label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0858a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "right = 0\n",
    "test_acc = 0\n",
    "\n",
    "for i in range(len(label)):\n",
    "    right = np.sum(label[i]==pred[i])\n",
    "    test_acc = test_acc + right\n",
    "\n",
    "print(f\"The obtained accuracy is {test_acc/len(label)*100} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0237d0c3",
   "metadata": {},
   "source": [
    "en 5 clases a ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111887aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = np.loadtxt('./Modelos_Fiteados/REG/predic_3C_L1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5320bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for i in range(len(prediccion)):\n",
    "    if -60<= prediccion[i,0]< -36:\n",
    "        prediccion[i,0]=0\n",
    "    elif -36 <= prediccion[i,0] < -12:\n",
    "        prediccion[i,0]=1\n",
    "    elif -12<= prediccion[i,0] < 12:\n",
    "        prediccion[i,0]=2\n",
    "    elif 12 <= prediccion[i,0] < 36:\n",
    "        prediccion[i,0]=3\n",
    "    else:\n",
    "        prediccion[i,0]=4        \n",
    "        \n",
    "i=0\n",
    "for i in range(len(prediccion)):\n",
    "    if -60 <= prediccion[i,1]< -36:\n",
    "        prediccion[i,1]=0\n",
    "    elif -36 <= prediccion[i,1] < -12:\n",
    "        prediccion[i,1]=1\n",
    "    elif -12<= prediccion[i,1] < 12:\n",
    "        prediccion[i,1]=2\n",
    "    elif 12 <= prediccion[i,1] < 36:\n",
    "        prediccion[i,1]=3\n",
    "    else:\n",
    "        prediccion[i,1]=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4542ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = prediccion[:,0]\n",
    "pred = prediccion[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afba863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confussion_plot(real, prediction):\n",
    "    categories = ['Clase 1', 'Clase 2', 'Clase 3', 'Clase 4', 'Clase 5']\n",
    "\n",
    "    array = confusion_matrix(real, prediction, normalize=\"true\")\n",
    "    df_cm = pd.DataFrame(array, index = [i for i in categories], columns = [i for i in categories])\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,7))\n",
    "    sn.heatmap(df_cm, annot=True, fmt='.2f', cmap='viridis')\n",
    "    plt.ylabel(\"Etiqueta\",fontsize=15)\n",
    "    plt.xlabel(\"Predicción\",fontsize=15)\n",
    "    plt.title(\"Matríz de confusión\",fontsize=15)\n",
    "    plt.savefig('./Modelos_Fiteados/Imagenes/REG/MC3CL1_5_NORM.png', format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f468fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "confussion_plot(label, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abb637c",
   "metadata": {},
   "source": [
    "#### Veamos si me sale el grafico delas cosas pero con la recta ajustada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a5a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = -0.0064\n",
    "b = 1.009\n",
    "\n",
    "x = np.arange(-0.6,0.6, 0.001)\n",
    "y = a + b*x\n",
    "\n",
    "# plt.plot(x,y)\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('y')\n",
    "# plt.title('Lab DLS')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8148754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = np.loadtxt('./Modelos_Fiteados/REG/predic_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25c9ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(prediccion[:,0],prediccion[:,1], marker=\"+\", color='navy', s=5, alpha=.2)\n",
    "plt.plot(np.linspace(-0.6, 0.6, num=100),np.linspace(-0.6, 0.6, num=100), linestyle='--', color='sandybrown')\n",
    "plt.scatter(x,y, marker ='*' , color = 'darkviolet', s=5, alpha=0.5)\n",
    "plt.xlabel('Valor predicho',fontsize=15)\n",
    "plt.ylabel('Valor real',fontsize=15)\n",
    "plt.title(\"Dispersión 2C_L1\",fontsize=15)\n",
    "plt.xlim(-0.8,0.8)\n",
    "plt.legend(labels = ['Puntos','Identidad','Ajuste'])\n",
    "# plt.savefig('./Modelos_Fiteados/Imagenes/REG/disper_3c_L1.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b327244f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
